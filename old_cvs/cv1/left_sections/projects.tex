\cvsection{PROJECTS \& ACHIEVEMENTS}


\cvevent
    {Published Papers and Microsoft Collaboration}  % title
    {SMLab and Microsoft Research India}  % Prof name/ lab name
    {June 2023 - July 2024}  % Dates
    {NISER}  % location
    \begin{justify}
        Worked on making more efficient (lottery tickets) pruned models using quaternion neural networks on large models. This led to some novel work which got published in the Northern Lights Deep Learning Conference in January 2024. On the basis of this work got to work with MSR India and built some efficient models for industrial purposes. During this time I managed to make some really efficient transformer models which resulted in a second paper which again got accepted in NLDL this year.
    \end{justify}
    \divider


\cvevent
    {Won the ML4SCI Hackathon}  % title
    {ML4SCI Hackathon}  % Prof name/ lab name
    {Nov 2021 - Jan 2022}  % Dates
    {Online}  % location
    \begin{justify}
        Dominated the \textbf{Higgs Challenge} in the prestigious \textbf{ML4SCI Hackathon}, leveraging my skills in \textbf{machine learning and big data analytics} to achieve a groundbreaking \textbf{ROC AUC of 0.88} on a dataset with over 11 million data points. Pioneered an ensemble approach, combining five neural networks (NNs) and XGBoost to accurately predict the presence of the Higgs boson in this highly competitive challenge. The competition demonstrated exceptional ability in \textbf{ensemble modeling, feature engineering, and large-scale data processing}, propelling our team to first place. This victory highlights my expertise in handling complex datasets, optimizing models, and applying advanced machine learning techniques to solve real-world scientific problems.  
        \href{https://github.com/PeithonKing/ML_comp}{\textbf{[More]}}
    \end{justify}
    \divider



\cvevent
    {Machine Learning Internship}  % title
    {Prof. Kripabandhu Ghosh}  % Prof name/ lab name
    {Dec 2021 - Jul 2022}  % Dates
    {IISER Kolkata}  % location
    \begin{justify}
        Gained hands-on experience in cutting-edge \textbf{Natural Language Processing (NLP)} and \textbf{Information Retrieval} systems as part of a research-focused internship. Worked on complex algorithms for document sorting based on query relevance, optimizing search and retrieval processes across vast corpora. Enhanced understanding of various NLP techniques, including tokenization, vectorization, and semantic understanding. Developed scoring algorithms for document ranking, achieving a significant improvement in performance with a MAP score of 0.21 for the AILA dataset (previous maximum: 0.14). Contributed to several impactful advancements in \textbf{AI-driven information retrieval systems}, demonstrating expertise in \textbf{machine learning deployment} in real-world applications.  
        \href{https://github.com/PeithonKing/AILA}{\textbf{[More]}}
    \end{justify}
    \divider


\cvevent
    {Improvement on the Quaternion-based models: extension to larger datasets and models}  % title
    {Prof. Subhankar Mishra}  % Prof name/ lab name
    {Jan - July 2023}  % Dates
    {NISER, SM Lab}  % location
    \begin{justify}
        Investigated the Lottery Ticket Hypothesis (LTH) applied to large quaternion based ResNet models for datasets like Cifar100 and ImageNet. Demonstrated that quaternion models maintain better accuracy retention during pruning compared to traditional real-valued models. This research provides insights into improving deep learning model efficiency through advanced pruning and model compression techniques.  
        \href{https://github.com/smlab-niser/quatLT23}{\textbf{[More]}}
    \end{justify}
    \divider


\cvevent
    {Importance Sampling and Machine Learning Approach for Classical Ising Model}  % title
    {Prof. Anamitra Mukherjee}  % Prof name/ lab name
    {Aug 2024 - Present}  % Dates
    {NISER}  % location
    \begin{justify}
        Currently exploring innovative \textbf{machine learning techniques} to enhance classical statistical models, specifically the Ising Model. Focused on generating extensive lattice configurations at varying temperatures and Hamiltonians using \textbf{importance sampling} methods. The goal is to leverage \textbf{machine learning models} to predict physical quantities directly, significantly reducing the need for computationally expensive simulations. This approach aims to advance our ability to solve complex problems in \textbf{statistical physics} while optimizing computational resources.  
        \href{https://sites.google.com/site/workpagetemp/group-members}{\textbf{[More]}}
    \end{justify}
    \divider


\cvevent
    {Quantum Cryptography Experience}  % title
    {Prof. Prasanta K. Panigrahi (IISER Kolkata) \& Qkrishi}  % Prof name/ lab name
    {Summer 2022}  % Dates
    {IISER Kolkata}  % location
    \begin{justify}
        During the summer of 2022, I advanced my expertise in \textbf{quantum cryptography} through an internship at IISER Kolkata and an advanced course by \textbf{IISER Tirupati} and \textbf{Qkrishi}. My focus was on the theoretical and practical applications of \textbf{quantum key distribution (QKD)}, specifically \textbf{BB84} and \textbf{E91} protocols, to ensure secure communication in the presence of an eavesdropper (Eve). I explored both \textbf{symmetric and asymmetric key cryptography} within the quantum framework, leveraging the power of \textbf{quantum entanglement} and \textbf{superposition} to create unbreakable encryption keys. Using \textbf{Qiskit} and \textbf{Flask}, I simulated these quantum protocols and demonstrated their resilience against eavesdropping, providing an ultimate solution to classical cryptography vulnerabilities.  
        \href{https://github.com/PeithonKing/Attacking_QKD_Protocols}{\textbf{[QKD Project]}} \& \href{https://peithonking.github.io/Quantum_Robot_LaTEX/quantum_robot_internship_report.pdf}{\textbf{[Internship Report]}}
    \end{justify}
    % \divider


